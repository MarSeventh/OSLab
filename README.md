# Lab4 实验报告

[TOC]

## 一、思考题

### 1、思考并回答下面的问题：

###  • 内核在保存现场的时候是如何避免破坏通用寄存器的？

###  • 系统陷入内核调用后可以直接从当时的 $a0-$a3 参数寄存器中得到用户调用 msyscall 留下的信息吗？

###  • 我们是怎么做到让 sys 开头的函数“认为”我们提供了和用户调用 msyscall 时同样 的参数的？ 

### • 内核处理系统调用的过程对 Trapframe 做了哪些更改？这种修改对应的用户态的变 化是什么？

```
1、将通用寄存器的值存入Trapframe当中，这样在之后的操作中便不需要考虑破坏通用寄存器的问题。
2、不能，陷入内核调用后$a0-$a3会发生改变，应该从保存的Trapframe中读取msyscall留下的信息。
3、调用sys开头的函数时，参数由do_syscall函数读取栈中的值进行传递，因此读取到的参数和用户调用时一样。
4、在do_syscall中会修改Trapframe的regs[2]及$v0的值，作为调用返回值。除此之外。还会修改Trapframe中cp0_epc的值，使其增加一个字长，表示返回后从系统调用的下一条指令开始执行。
```

### 2、思考 envid2env 函数: 为什么 envid2env 中需要判断 e->env_id != envid 的情况？如果没有这步判断会发生什么情况？

```
该判断是为了保证根据envid找到的Env结构体是有效的，否则可能取出数组中的一个空闲的Env结构体，他并不代表一个进程，返回后会造成调用进程错误判断，从而导致程序出错。
```

### 3、思考下面的问题，并对这个问题谈谈你的理解：请回顾 kern/env.c 文件 中 mkenvid() 函数的实现，该函数不会返回 0，请结合系统调用和 IPC 部分的实现与 envid2env() 函数的行为进行解释。

```C
由于mkenvid()函数不会返回0，所以所有的有效的Env中env_id都不会是0，从而我们可以约定在后续的函数调用中如果出现参数envid且其值为0，则将其视作表示当前进程。例如，在envid2env中出现envid==0时，则将penv指向当前进程的Env并直接返回。
121         if(envid == 0){
122                 e = curenv;
123                 if(e->env_status == ENV_FREE) return -E_BAD_ENV;
124                 *penv = e;
125                 return 0;
126         }else{
127                 e = &envs[ENVX(envid)];
128         }
```

### 4、关于 fork 函数的两个返回值，下面说法正确的是：

###  A、fork 在父进程中被调用两次，产生两个返回值

###  B、fork 在两个进程中分别被调用一次，产生两个不同的返回值

###  C、fork 只在父进程中被调用了一次，在两个进程中各产生一个返回值 

###  D、fork 只在子进程中被调用了一次，在两个进程中各产生一个返回值

```
根据fork()函数的实现，我们可以得到本题答案为C。
由于父子进程在从内核态返回用户态时，经历了同样的恢复运行现场过程，都会从内核返回到msyscall函数，但是它们现场中存储的返回值（&v0寄存器的值）是不同的，这个值最后再返回到syscall_exofork和fork函数，使得fork函数拥有了两个不同的返回值，用于区分父子进程。
```

### 5、我们并不应该对所有的用户空间页都使用 duppage 进行映射。那么究竟哪 些用户空间页应该映射，哪些不应该呢？请结合 kern/env.c 中 env_init 函数进行的页 面映射、include/mmu.h 里的内存布局图以及本章的后续描述进行思考。

```C
应该映射的是USTACKTOP以下的部分，根据env_init中的描述：
    
174          /* We want to map 'UPAGES' and 'UENVS' to *every* user space with PTE_G permission (without
175          * PTE_D), then user programs can read (but cannot write) kernel data structures 'pages' and
176          * 'envs'.
177          *
178          * Here we first map them into the *template* page directory 'base_pgdir'.
179          * Later in 'env_setup_vm', we will copy them into each 'env_pgdir'.
180          */
181         struct Page *p;
182         panic_on(page_alloc(&p));
183         p->pp_ref++;
184 
185         base_pgdir = (Pde *)page2kva(p);
186         map_segment(base_pgdir, 0, PADDR(pages), UPAGES, ROUND(npage * sizeof(struct Page), BY2PG),
187                     PTE_G);
188         map_segment(base_pgdir, 0, PADDR(envs), UENVS, ROUND(NENV * sizeof(struct Env), BY2PG),
189                     PTE_G);

我们可以看出UPAGES和UENVS已经事先复制到了每个进程的env_pgdir中，所以无需在创建子进程时再次进行映射。
因此，我们在fork函数中使用duppage处写法如下：
    
            for(int vpn = 0; vpn < USTACKTOP; vpn += BY2PG){
129                 if((vpd[vpn >>PDSHIFT] & PTE_V) && (vpt[vpn >> PGSHIFT] & PTE_V)){
130                         duppage(child, VPN(vpn));
131                 }
132         }
```

### 6、在遍历地址空间存取页表项时你需要使用到 vpd 和 vpt 这两个指针，请参 考 user/include/lib.h 中的相关定义，思考并回答这几个问题：

###  • vpt 和 vpd 的作用是什么？怎样使用它们？ 

### • 从实现的角度谈一下为什么进程能够通过这种方式来存取自身的页表？

###  • 它们是如何体现自映射设计的？

###  • 进程能够通过这种方式来修改自己的页表项吗？

```c
#define vpt ((volatile Pte *)UVPT)                                                                  #define vpd ((volatile Pde *)(UVPT + (PDX(UVPT) << PGSHIFT)))
1、vpt是进程自己的页表的基地址，vpd则是进程自己的页目录的基地址。我们可以通过类似于数组的方式使用它们，例如vpt[i]是用户空间第i个页表项的值，而vpd[i]是第i个页目录项的值。
2、因为我们在构造每个进程的时候都将其自身的页表基地址映射到了UVPT的位置，所以就可以通过直接访问该地址来获得页表的值，又由于页目录自映射的性质，便可以通过vpd来直接访问页目录的值。
3、vpt首先使用UVPT访问到页目录自身的物理地址，然后再通过数组的角标访问到对应的页表（二级页表）以及页表中对应的页表项；而vpd则首先通过UVPT访问到页目录自身的物理地址，再通过UVPT访问到页目录自身的物理地址（二级页表），最后再通过对应的角标获取到相应的页目录项。
4、进程可以通过这种方式来访问并且修改自己的页表项。
```

### 7、在 do_tlb_mod 函数中，你可能注意到了一个向异常处理栈复制 Trapframe 运行现场的过程，请思考并回答这几个问题： 

### • 这里实现了一个支持类似于“异常重入”的机制，而在什么时候会出现这种“异常重 入”？

###  • 内核为什么需要将异常的现场 Trapframe 复制到用户空间？

```
1、因为我们想要在用户空间处理该异常，但是由于目前的运行现场保存在内核栈当中，用户空间无法访问，因此需要将运行现场复制到用户空间的“异常处理栈”当中，从而便出现了这样一种类似于“异常重入”的机制。
2、因为微内核的理念，我们想要在用户空间处理该异常，其处理函数位于用户空间，因此要将异常现场复制到用户空间。
```

### 8、在用户态处理页写入异常，相比于在内核态处理有什么优势？ 

```
1、更加灵活且可定制：用户态的异常处理代码由程序自己给出，可以更加贴合自己的要求，实现更复杂的功能，并且不同程序的异常处理方式可以不同，灵活性更高。
2、安全性更高：用户态的异常处理程序只能访问自身受保护的用户空间，不会影响内核和其他进程的正常执行，这使得系统的安全性和健壮性更好。
```

### 9、请思考并回答以下几个问题：

###  • 为什么需要将 syscall_set_tlb_mod_entry 的调用放置在 syscall_exofork 之前？ 

### • 如果放置在写时复制保护机制完成之后会有怎样的效果？

```
1、为了保证父进程设置的tlb_mod_entry是自己的页写入异常处理函数，而不是子进程的处理函数。
2、会导致父进程设置的tlb_mod_entry与子进程完全相同，是子进程的异常处理函数。可能导致程序出现不可预测的错误。
```

## 二、实验难点

本次实验的难度相较于前几次有了较大的提升，并且难度主要集中在fork函数的实现部分，在fork函数实现部分需要我们清楚子进程是如何产生的，同时还要掌握写时复制技术的概念与实现方法，除此之外还要掌握在用户空间处理异常的方式，这几个点无论是从理解还是从实现角度来说都不是很容易。相比之下，系统调用的实现和进程间通信IPC的实现虽然难度没有那么高，但是它们也是操作系统内核的基础，掌握其思想具有重要的意义。

下面，我将分点对本次实验的几个难点以及重点进行说明：

### 1、系统调用的实现

系统调用的实现，基本都遵循以下流程：

> ![image-20230427212323695](C:\Users\King.xx\AppData\Roaming\Typora\typora-user-images\image-20230427212323695.png)

简单地说，一个系统调用的实现需要分为用户态的执行操作和内核态的执行操作。用户态的syscall\_\*函数和内核态的sys\_\*函数一一对应，syscall\_\*函数主要负责将将传入的参数压入栈帧，然后调用msyscall函数，并将参数传递给它。msyscall函数只需调用syscall陷入内核态然后返回即可。陷入内核态后，entry.S中的SAVE_ALL首先会把用户态的运行现场保存在Trapframe中，然后将其指针作为参数传递给handle_sys函数，该函数会调用do\_syscall函数，该函数通过传入的Trapframe来从异常向量表中选取相应的处理函数sys\_\*，将Trapframe中保存的参数传递给sys\_\*，然后sys\_\*执行对应的系统调用操作。完成操作之后返回到用户态的执行现场。

可以发现，这一流程看似繁琐，但是关键函数就是do\_syscall和具体执行的sys\_\*两个函数，理清楚执行思路之后还是比较容易掌握的。

### 2、进程间通信机制（IPC）

进程间通信机制，顾名思义就是要实现两个进程之间的消息传递。由于不同进程的用户空间相互独立，但是内核空间却共用一个，所以我们自然而然地想到利用内核空间作为我们的“中转站”来进行消息的传递。有了这一思想之后，IPC的实现也就不是很难了。

IPC的流程图如下：

> ![image-20230427220137680](C:\Users\King.xx\AppData\Roaming\Typora\typora-user-images\image-20230427220137680.png)

主要就是实现sys\_ipc\_recv和sys\_ipc\_try\_send两个函数，分别负责消息的接收和传递。这两个函数在自己的用户态下设定好需要发送或接收的状态后，都会进行系统调用来讲数据写入内核或者从内核读出数据，这样也就实现了两个进程之间的消息通信。

### 3、fork函数的实现

fork函数作为本次实验最难的一部分，其实现也比较复杂，我们首先观察fork函数的流程图，了解其大致过程。

> ![image-20230427220638286](C:\Users\King.xx\AppData\Roaming\Typora\typora-user-images\image-20230427220638286.png)

根据流程图，我们来依次分析其中几个关键点。

#### 3.1fork返回值的确定

fork函数具有一大特性，就是它执行一次会产生两个返回值，用以区分返回到的是父进程还是子进程。若返回到父进程中，其返回值是子进程的id；若返回到子进程中，其返回值则为0。那么我们要如何实现这样的特性呢，这就与fork函数内部调用的exofork这一函数有关，该函数负责陷入内核态创建一个新进程，然后再返回用户态。由于我们的子进程是父进程的副本，因此他们从内核态返回的过程基本一致，都会返回到msyscall中，进而返回到exofork和fork中，我们只需要保证父进程和子进程从内核态返回用户态时$v0这个寄存器的值不同便可以实现fork函数的两个返回值这一特性。

#### 3.2地址空间的复制

为了节省物理内存，我们的实验采用了一种写时复制机制，简单来说就是先对所有子进程可能更改的物理页进行标记，一旦父进程或者子进程需要更改该页的内容，就直接将该页复制一份，改变映射关系之后进行修改，否则就使两进程共用一份物理页。可以看到，要实现这一机制其实主要就是实现两个环节，即旧页面的标记和写入异常的处理。

对于旧页面的标记，我们实现了duppage函数，在对用户空间的所有页面进行遍历的同时，给满足条件的页面加上写时复制标记。需要注意的是，在遍历的过程中我们通过vpt和vpd这两个指针大大简化了代码的复杂度，而这两个指针和我们之前使用的页目录自映射机制有着密不可分的关系，具体可以看上文中的6个思考题。

对于页写入异常处理，我们实现了一种在用户态下处理异常的模式。这就要求我们实现使用env\_user\_tlb\_mod\_entry这一函数指定每个进程自己的页写入异常处理函数的地址，然后在发生页写入异常时，内核只要负责将进程现场保存在进程的异常处理栈当中，然后将控制权交回用户态进程，让进程调用自己的页写入异常处理函数即可。

## 三、心得体会

在本次实验中，我对于IPC及之前的部分完成得还是比较顺利的，因为这半部分各个函数实现的功能相对比较独立，实现和测试都比较清晰明了。但是后半部分fork的实现就完全不同了，可以说后半部分所有的函数都是互相关联的，并且都为fork函数服务，所以一旦某个函数出现了小小的bug就可能会影响到整个fork函数的执行。而我就是因为在遍历所有页并且调用duppage时出现了未判断有效位的问题以及在duppage中没有正确取得相应页表项的perm的问题导致程序迟迟不能正确运行，调试花费了较长的时间。

但是，尽管这次实验有一定难度，做完本次实验后收获还是很大的。

首先就是对用户态和内核态这两个概念有了更加深刻的理解。通过在本次实验中实现系统调用、IPC等功能多次进行了内核态和用户态的衔接，我对于两者切换时进行的运行现场保护，运行现场恢复等功能了解得更加透彻。同时，我也知道了内核态和用户态切换与进程之间切换的重大不同，很明显地能够看出内核态和用户态的切换高效得多。

其次就是我对于内存的布局，页表和页目录等内容的了解更进一步。由于在使用vpt和vpd这两个指针的时候迟迟不能理解它们的作用，我又对内存布局图和页目录自映射等内容进行了回顾和进一步思考，清楚了UVPT的重要作用，也知道了vpt和vpd这两者使用的巧妙之处。

最后就是对fork函数和写时复制等内容了解更为透彻。之前总是不懂fork函数为什么会有两个返回值，经过实验之后我知道了这是通过两个进程从内核返回时不同的$v0决定的。除此之外，我还知道了写时复制的实现方式以及它对于节省内存的重要作用。
